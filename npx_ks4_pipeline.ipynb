{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated spike sorting, quality metrics, and data alignment. \n",
    "This is a pipeline which spike-sorts neuropixel data aquired with [SpikeGLX](https://billkarsh.github.io/SpikeGLX/) and task control via either [NIMH MonkeyLogic](https://monkeylogic.nimh.nih.gov/index.html) or [PsychToolbox](https://psychtoolbox.org/). \n",
    "\n",
    "It uses [Kilosort 4](https://github.com/MouseLand/Kilosort) and KS4 must already be installed on this machine.\n",
    "\n",
    "This program will:\n",
    "- preprocess your spiking data (e.g. correcting for multiplexing error)\n",
    "- spike sort your data (via Kilosort 4)\n",
    "- generate basic quality metrics for each putative unit identified by KS4\n",
    "- extract and resample the LFP data (data are resampled at 1000 Hz)\n",
    "- extract 8 bit digital words used to mark specific [task events](https://monkeylogic.nimh.nih.gov/docs_RuntimeFunctions.html#eventmarker)\n",
    "- extract [sync edges](https://billkarsh.github.io/SpikeGLX/help/syncEdges/Sync_edges/) associated with each data stream \n",
    "- map all of your data into a common timeline (the clock of your first neuropixels probe - imec0).\n",
    "\n",
    "All data are then saved in their original directories. \n",
    "\n",
    "**Notes:** \n",
    "- This pipeline is optimized for data acquisition with [SpikeGLX](https://billkarsh.github.io/SpikeGLX/) where each probe has its own folder\n",
    "- You must use (activate) the 'kilosort' environment you created when installing KS4\n",
    "- You must use a version of numpy less than 2.0. To do this, navigate to the anaconda prompt and `uninstall numpy` and then `pip install numpy==1.24.0`\n",
    "\n",
    "This version was created by [Thom Elston](https://www.thomelston.com/) in June 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kilosort as ks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import neuropixel_preprocessing_module as npm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = Path('E:/D20231212_Rec03_g0/') # highest level folder for this recording\n",
    "brain_areas = ['CdN', 'OFC'] # which brain area is probe 0 and 1?\n",
    "run_spike_sorter = True # set to false if you want to only run alignment or skip sorting for some reason\n",
    "channel_map = 'neuropixPrimate_kilosortChanMap.mat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main routines run below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subfolders for each probe\n",
    "probe_folders = [folder for folder in base_folder.glob('*') if folder.is_dir()]\n",
    "\n",
    "# save csv with info about which probe was in which brain area\n",
    "pd.DataFrame(brain_areas, columns=['brain_area']).to_csv(base_folder / 'brain_areas.csv')\n",
    "\n",
    "# initialize a list to accumulate the names of the sync_files into\n",
    "# - these are what are used to map data into a common timeline\n",
    "sync_files = []\n",
    "data_stream_info = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading E:\\D20231212_Rec03_g0\\D20231212_Rec03_g0_imec0 in CdN\n",
      "\n",
      "File path E:\\D20231212_Rec03_g0\\D20231212_Rec03_g0_imec0\\D20231212_Rec03_g0_t0.imec0.ap.bin\n",
      "\n",
      "Quality metrics saved\n",
      "\n",
      "Probe 0 complete\n",
      "\n",
      "\n",
      "Loading E:\\D20231212_Rec03_g0\\D20231212_Rec03_g0_imec1 in OFC\n",
      "\n",
      "File path E:\\D20231212_Rec03_g0\\D20231212_Rec03_g0_imec1\\D20231212_Rec03_g0_t0.imec1.ap.bin\n",
      "\n",
      "Quality metrics saved\n",
      "\n",
      "Probe 1 complete\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Kilosort 4 run settings (sample rate will be modified later for each probe)\n",
    "settings = {'n_chan_bin': 385, 'fs': 30000}\n",
    "\n",
    "# Start looping over each probe\n",
    "for i in range(len(probe_folders)):\n",
    "\n",
    "    probe_dir = probe_folders[i]\n",
    "    probe_path = npm.get_path_from_dir(probe_dir, 'ap.bin')\n",
    "    i_brain_area = brain_areas[i]\n",
    "\n",
    "    print('Loading ' + str(probe_dir) + ' in ' + str(i_brain_area) + '\\n')\n",
    "    print('File path %s\\n' % str(probe_path))\n",
    "\n",
    "    # collect the name of the sync_files for later\n",
    "    sync_files.append(npm.get_path_from_dir(probe_dir, 'lf.bin'))\n",
    "    data_stream_info.append('imec'+ str(i))\n",
    "    \n",
    "    probe_meta = npm.readMeta(probe_path) # read in probe meta data\n",
    "    settings['fs'] = float(probe_meta['imSampRate']) # set probe sample rate\n",
    "    \n",
    "    results_dir = probe_dir / 'ks4_out/sorter_output' # set Kilosort results directory\n",
    "    results_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if run_spike_sorter:\n",
    "    # run Kilosort 4\n",
    "        ks.run_kilosort(settings=settings, filename=probe_path, probe_name=channel_map, results_dir=results_dir)\n",
    "        print('Sorting complete!' + '\\n')\n",
    "\n",
    "        # Read in probe-specific timing info from the meta data\n",
    "        fs = float(probe_meta['imSampRate']) # sampling rate, in Hz\n",
    "        rec_length = float(probe_meta['fileTimeSecs']) # recording duration (in s)\n",
    "\n",
    "        # compute some quality metrics\n",
    "        print('Computing quality metrics...' + '\\n')\n",
    "        npm.compute_basic_quality_metrics(results_dir, fs, rec_length)\n",
    "\n",
    "    print('Quality metrics saved\\n')\n",
    "    print('Probe %i complete\\n\\n' % i) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now extract the sync edges and map the spike times to a reference timeline\n",
    "\n",
    "**NOTE:** This assumes that analog channel 0 is used as the sync data stream for the nidaq stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting sync edges...\n",
      "\n",
      "n_channels: 385, n_file_samples: 8722216\n",
      "n_channels: 385, n_file_samples: 8722303\n",
      "n_channels: 9, n_file_samples: 36958451\n",
      "\n",
      "Sync edge times saved in original directory.\n",
      "\n",
      "Extracting event codes from nidq stream...\n",
      "\n",
      "n_channels: 9, n_file_samples: 36958451\n",
      "\n",
      "Event codes saved in original directory.\n"
     ]
    }
   ],
   "source": [
    "# add the nidaq data to sync_files and now extract the edges associated with each data stream. \n",
    "sync_files.append(npm.get_path_from_dir(base_folder, 'nidq.bin'))\n",
    "data_stream_info.append('nidq')\n",
    "npm.extract_sync_edges(sync_files)\n",
    "\n",
    "# extract 8 bit event words to mark task events (from e.g. MonkeyLogic or Psych Toolbox)\n",
    "npm.extract_event_codes(npm.get_path_from_dir(base_folder, 'nidq.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping spikes and task events to a common timeline.\n",
      "\n",
      "imec0 set as master timeline.\n",
      "aligning: E:\\D20231212_Rec03_g0\\D20231212_Rec03_g0_imec0\n",
      "aligning: E:\\D20231212_Rec03_g0\\D20231212_Rec03_g0_imec1\n",
      "aligning: E:\\D20231212_Rec03_g0\n",
      "\n",
      "Aligned spikes and event codes saved in their original directories.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# map your spike and event code data into a common timeline\n",
    "npm.align_data_streams(sync_files, data_stream_info, 0, ks_ver='4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting and mapping LFPs to a common timeline.\n",
      "\n",
      "imec0 set as master timeline.\n",
      "aligning: E:\\D20231212_Rec03_g0\\D20231212_Rec03_g0_imec0\n",
      "n_channels: 385, n_file_samples: 8722216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\D20231212_Rec03_g0\\D20231212_Rec03_g0_imec0: 100%|██████████| 385/385 [02:13<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning: E:\\D20231212_Rec03_g0\\D20231212_Rec03_g0_imec1\n",
      "n_channels: 385, n_file_samples: 8722303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\D20231212_Rec03_g0\\D20231212_Rec03_g0_imec1: 100%|██████████| 385/385 [02:09<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aligned and downsampled LFPs saved in their original directories.\n"
     ]
    }
   ],
   "source": [
    "# extract and align the LFP streams\n",
    "npm.align_LFP_streams(sync_files, data_stream_info, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
